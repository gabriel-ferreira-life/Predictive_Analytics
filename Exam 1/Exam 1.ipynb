{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264dcf1f",
   "metadata": {},
   "source": [
    "### 1. True or False.\n",
    "(a) In class imbalanced classification tasks, the goal is to find the model that has the highest accuracy. (True False)\n",
    "### False\n",
    "\n",
    "(b) Over-fitting is the biggest issue with over-sampling. (True False)\n",
    "### True\n",
    "\n",
    "(c) Under-fitting is the biggest issue with over-sampling. (True False)\n",
    "### False\n",
    "\n",
    "(d) A model with a large number of input variables always have a good performance. (True False)\n",
    "### False\n",
    "\n",
    "(e) If we run the SMOTE sampling technique multiple times on an imbalanced dataset, we will always obtain the same synthetic dataset. (True False) \n",
    "### False\n",
    "\n",
    "(f) Having access to good data is better than having a good model. (True False)\n",
    "### True\n",
    "\n",
    "(g) RFE works with any support vector machine model. (True False)\n",
    "### False\n",
    "\n",
    "(h) RFE doesn’t work with any support vector machine model. (True False)\n",
    "### False\n",
    "\n",
    "(i) A typical approach to engineer features is to consider interactions because most interactions help models to generate good predictions. (True False)\n",
    "### True\n",
    "\n",
    "(j) The support vectors in support vector machine models can be used to identify important variables/featues. (True False)\n",
    "### False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046970cb",
   "metadata": {},
   "source": [
    "### 2. How does the Recursive Feature Elimination (RFE) algorithm work? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fd264",
   "metadata": {},
   "source": [
    "The Recursive Feature Elimination (RFE) algorithm works basically as a backward selection of the predictors. This technique begins building a model with all set of predictors and computing an importance score for each predictor. The least important predictor(s) are removed, then the process repeat again. The analyst usually specifies the number of predictor to be used in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35903ffa",
   "metadata": {},
   "source": [
    "### 3. Explain one-hot encoding. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d37c4",
   "metadata": {},
   "source": [
    "One-hot enconding is the proccess of creating numeric dummies variables out of a multi-class variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4bd3e",
   "metadata": {},
   "source": [
    "### 4. If you have a date column in your data-frame, then how will you perform feature engineering on the date column? List at least three features that you will engineer from date. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80eb130",
   "metadata": {},
   "source": [
    "Having a date column in my data-frame, I could engineer a feature to store the month, it would facilitate the subseting of the data if needed. In the same logic, I could engineer a feature to sotre the year. I could also extract the day name (Sun, Mon, Tue, Wed, Thu, Fri, Sat). From there, I could engineer features about whether it was a week or weekend. Holiday or not, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf904eda",
   "metadata": {},
   "source": [
    "### 5.  In what scenarios, would you prefer to use the precision-recall curve instead of ROC curve to measure the performance of a classifier? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8785cf",
   "metadata": {},
   "source": [
    "I would prefer to use the precision-recall curve instead of ROC curve to measure the performance of a classifier when the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ef8e9",
   "metadata": {},
   "source": [
    "### 6. Explain the biggest drawback of one-vs-one multi-class classification when compared to one-vs-all multi-class classification. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6326d8",
   "metadata": {},
   "source": [
    "The biggest draw drawback of one-vs-one multi-class classification when compared to one-vs-all multi-class classification is because one-vs-one is harder to interprete and less efficient than one-vs-all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec3e7e",
   "metadata": {},
   "source": [
    "### 7. A data scientist is building a linear regression model. One of the input variables is a categorical variable with three labels. So, he decided to use the one-hot encoding approach to transform the categorical variable into dummy variables. How many dummy variables does he need to include in the linear model?\n",
    "(a) 0\\\n",
    "(b) 1\\\n",
    "(c) 2 \\\n",
    "(d) 3 \\\n",
    "(e) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a346b",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "(c) 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ff414",
   "metadata": {},
   "source": [
    "### 8. Suppose you are building a fraud detection system for major US bank. You have access to all the transaction data for the past week for users (date, location, and amount).What kind of new features can you engineer? Be creative and list at least three features that you would engineer for the fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3866a",
   "metadata": {},
   "source": [
    "Using date, I would engineer the day name of the week, and whether it was a week or weekend transaction. Using location, I could extract the demographic data from the rigion and create some type of risk measurement of the area. For example, a transaction in São Paulo, BRA would have a much hiher risk than a transaction in Iowa, USA. Also, a dummy variable to sotre an information about whether it was a transaction within the \"normal\" location range that the user usually act. Lastly, I would flag in a dummy variable all transactions that were outside of the range the user usually expend. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c154a",
   "metadata": {},
   "source": [
    "### 9. The chart below was constructed using data related to credit card payments of college students. On the x-axis, we have the credit card balance, and on the y-axis we have the college students’ incomes. The light-blue circles represent payments that didn’t default; on the other hand, the orange circles represent credit card payments that default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae09c8",
   "metadata": {},
   "source": [
    "### Let’s assume that you are the data scientist in charge of this project. The goal is to build a classification system that can flag future credit card payments that are likely to default. Answer the following:\n",
    "### (a) Is the dataset imbalanced? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdacbd",
   "metadata": {},
   "source": [
    "This dataset is imbalanced because the light-blue circles have a very high proportion when compared to the orange circles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbfa84",
   "metadata": {},
   "source": [
    "### (b) Using the above chart, engineer one feature for your classification model. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34845",
   "metadata": {},
   "source": [
    "I would engineer a feature to store the interaction between Income and Balance by multiplying them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff1a0",
   "metadata": {},
   "source": [
    "### 10. Which of the following is/are TRUE feature subset selection?\n",
    "(a) Subset selection can substantially decrease the bias of support vector machine models.\\\n",
    "(b) Ridge regression frequently eliminates some of the features.\\\n",
    "(c) Subset selection can reduce over-fitting.\\\n",
    "(d) Finding the true best subset takes exponential time.\n",
    "\n",
    "### Answer:\n",
    "(c) Subset selection can reduce over-fitting.\\\n",
    "(d) Finding the true best subset takes exponential time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e4c49",
   "metadata": {},
   "source": [
    "### 11. A data scientist is building a regression model. A few of the input variables are categorical, and he has not looked at the distribution of the categorical data in the test data. The data scientist wants to apply the one-hot encoding on the categorical features. What challenges he may face if he have applied one-hot encoding on a categorical variable of the train dataset?\n",
    "\n",
    "(a) All categories of categorical variable are not present in the test dataset.\\\n",
    "(b) Frequency distribution of categories is different in train as compared to the test dataset.\\\n",
    "(c) Train and test always have same distribution.\\\n",
    "(d) (a) and (b)\\\n",
    "(e) (a) and (c)\\\n",
    "(f) (b) and (c)\\\n",
    "(g) None of the above.\n",
    "\n",
    "### Answer:\n",
    "(d) (a) and (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83895774",
   "metadata": {},
   "source": [
    "### 12. What is the difference between feature engineering and feature selection? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c7c09",
   "metadata": {},
   "source": [
    "Feature engineering is the process of creating new features from raw data and trasforming them into formats that are suitable for the machine learning model. While feature selection is the proccess of selecting the most important features for the machine learning model. Therefore, the difference between feature engineering and feature selection is that in feature engineering we are creating new features while in feature selection we are selecting the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f75bf7",
   "metadata": {},
   "source": [
    "### 13. Based on the discussions from Chapter 4, list at least two benefits of feature selection. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da7788",
   "metadata": {},
   "source": [
    "By performing feature selection, you will likely decrease the number of predictors/input variables, which automatically decreases the complexity of the model. In some cases, removing the predictors can reduce the cost of acquiring data or improve the throughput of the software used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa7aa1",
   "metadata": {},
   "source": [
    "### 14. Consider the F1-scores of three different classifiers in a 5-folds cross-validation setting (using the same test dataset) is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500e0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  Model 1  Model 2  Model 3\n",
       "0     1     0.76     0.81     0.75\n",
       "1     2     0.77     0.78     0.73\n",
       "2     3     0.78     0.78     0.76\n",
       "3     4     0.79     0.80     0.75\n",
       "4     5     0.76     0.79     0.73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold_cv = pd.DataFrame({'fold': [1, 2, 3, 4, 5], \n",
    "                        \"Model 1\": [0.76, 0.77, 0.78, 0.79, 0.76],\n",
    "                        \"Model 2\": [0.81, 0.78, 0.78, 0.80, 0.79],\n",
    "                        \"Model 3\": [0.75, 0.73, 0.76, 0.75, 0.73]})\n",
    "fold_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a07289",
   "metadata": {},
   "source": [
    "### Based on the F1-score, what model would use to make predictions? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43257d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 F1-score average:  0.772\n",
      "Model 2 F1-score average:  0.792\n",
      "Model 3 F1-score average:  0.744\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 F1-score average: \", fold_cv['Model 1'].mean())\n",
    "print(\"Model 2 F1-score average: \", fold_cv['Model 2'].mean())\n",
    "print(\"Model 3 F1-score average: \", fold_cv['Model 3'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde48f42",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "I would choose model 2 to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b751a",
   "metadata": {},
   "source": [
    "### 15. Consider the train.csv and test.csv data files. The train.csv data file contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "### (a)  Using the pandas library, read the train.csv and test.csv data files and create two data-frames, called them train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01087011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import precision_recall_cutoff # Calling .py function\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "git filter-branch -f --tree-filter 'rm -f Data_Mining_Cup_2019/test_dataset.csv' HEAD --all\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
