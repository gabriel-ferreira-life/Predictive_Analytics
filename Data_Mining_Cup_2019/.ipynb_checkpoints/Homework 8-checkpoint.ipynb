{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7a855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XGBoost in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from XGBoost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from XGBoost) (1.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a64e56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 44)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import precision_recall_cutoff\n",
    "import Ensemble\n",
    "from xgboost import XGBClassifier\n",
    "from cost_function import cost_function, cost_function_cutoff\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Reading the csv file\n",
    "train = pd.read_csv('train_dataset.csv')\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "test = pd.read_csv('test_dataset.csv')\n",
    "test = test.dropna()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81a38e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1879, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7936b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>interaction_1</th>\n",
       "      <th>interaction_4</th>\n",
       "      <th>heredity_1</th>\n",
       "      <th>interaction_9</th>\n",
       "      <th>heredity_2</th>\n",
       "      <th>interaction_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.848302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.317087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.026287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.640197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.833516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.834611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.416210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     totalScanTimeInSeconds  interaction_1  interaction_4  heredity_1  \\\n",
       "0                  0.472070            0.0            0.0         0.0   \n",
       "1                  0.104600            1.0            0.0         1.0   \n",
       "2                  0.848302            0.0            1.0         0.0   \n",
       "3                  0.317087            0.0            1.0         0.0   \n",
       "4                  0.066265            0.0            0.0         0.0   \n",
       "..                      ...            ...            ...         ...   \n",
       "371                0.026287            0.0            1.0         0.0   \n",
       "372                0.640197            0.0            0.0         0.0   \n",
       "373                0.833516            0.0            0.0         0.0   \n",
       "374                0.834611            0.0            1.0         0.0   \n",
       "375                0.416210            0.0            1.0         0.0   \n",
       "\n",
       "     interaction_9  heredity_2  interaction_5  \n",
       "0              0.0         0.0       0.818182  \n",
       "1              1.0         0.2       0.254545  \n",
       "2              0.0         0.0       0.000000  \n",
       "3              0.0         0.0       0.654545  \n",
       "4              0.0         0.0       0.272727  \n",
       "..             ...         ...            ...  \n",
       "371            0.0         0.0       0.436364  \n",
       "372            0.0         0.0       0.000000  \n",
       "373            0.0         0.0       0.000000  \n",
       "374            0.0         0.0       0.045455  \n",
       "375            0.0         0.0       0.200000  \n",
       "\n",
       "[376 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining input and target variables\n",
    "test = test[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9', 'heredity_2', 'interaction_5']]\n",
    "X = train[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9', 'heredity_2', 'interaction_5']]\n",
    "Y = train['fraud']\n",
    "\n",
    "# Splitting the data into train, test, and validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
    "\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_val = pd.DataFrame(X_val, columns = X.columns)\n",
    "\n",
    "\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220dedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining top 7, 6, and 5 variables\n",
    "# Train dataset\n",
    "X_train_7 = X_train\n",
    "X_train_6 = X_train[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9', 'heredity_2']]\n",
    "X_train_5 = X_train[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9']]\n",
    "\n",
    "# Validation dataset\n",
    "X_val_7 = X_val\n",
    "X_val_6 = X_val[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9', 'heredity_2']]\n",
    "X_val_5 = X_val[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9']]\n",
    "\n",
    "# Validation dataset\n",
    "test_7 = test\n",
    "test_6 = test[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9', 'heredity_2']]\n",
    "test_5 = test[['totalScanTimeInSeconds', 'interaction_1', 'interaction_4', 'heredity_1', 'interaction_9']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f35586",
   "metadata": {},
   "source": [
    "### The Best Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a71102f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.51481015e-03, 7.11261129e-02, 4.39258141e-03, 1.21666897e-04,\n",
       "       7.17944644e-03, 4.39258141e-03, 1.21666897e-04, 3.88108544e-01,\n",
       "       1.21666897e-04, 3.35681101e-04, 4.90534510e-03, 3.35681101e-04,\n",
       "       1.21666897e-04, 4.90534510e-03, 6.96543224e-03, 4.77390916e-03,\n",
       "       8.81121528e-02, 3.35681101e-04, 4.29561133e-03, 7.17944644e-03,\n",
       "       7.51481015e-03, 7.17944644e-03, 1.21666897e-04, 1.08437780e-01,\n",
       "       7.51481015e-03, 1.21666897e-04, 3.35681101e-04, 7.17944644e-03,\n",
       "       1.08785732e-02, 1.21666897e-04, 4.77390916e-03, 4.29561133e-03,\n",
       "       7.17944644e-03, 7.51481015e-03, 5.10803180e-03, 7.54612442e-02,\n",
       "       3.35681101e-04, 1.21666897e-04, 1.21666897e-04, 7.17944644e-03,\n",
       "       4.39258141e-03, 3.35681101e-04, 3.35681101e-04, 3.35681101e-04,\n",
       "       4.90534510e-03, 7.62446746e-02, 1.21666897e-04, 4.77390916e-03,\n",
       "       4.77390916e-03, 3.35681101e-04, 2.27807160e-02, 1.21666897e-04,\n",
       "       8.40301969e-03, 6.22246371e-02, 3.35681101e-04, 7.17944644e-03,\n",
       "       1.21666897e-04, 1.21666897e-04, 1.21666897e-04, 4.39258141e-03,\n",
       "       4.77390916e-03, 6.22246371e-02, 4.29561133e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 3.35681101e-04, 1.82531111e-01, 1.21666897e-04,\n",
       "       5.10803180e-03, 8.40301969e-03, 3.35681101e-04, 4.90534510e-03,\n",
       "       1.08885673e-01, 1.21666897e-04, 1.21666897e-04, 1.21666897e-04,\n",
       "       1.21666897e-04, 6.53528078e-02, 1.21666897e-04, 7.62528650e-02,\n",
       "       4.29561133e-03, 1.21666897e-04, 1.21666897e-04, 7.17944644e-03,\n",
       "       3.35681101e-04, 3.35681101e-04, 1.21666897e-04, 5.10803180e-03,\n",
       "       4.39258141e-03, 5.10803180e-03, 7.51481015e-03, 1.21666897e-04,\n",
       "       9.06542645e-02, 7.17944644e-03, 7.51481015e-03, 2.23693915e-01,\n",
       "       3.35681101e-04, 4.96543184e-03, 7.17944644e-03, 3.35681101e-04,\n",
       "       4.91926689e-03, 1.03602693e-01, 1.21666897e-04, 3.35681101e-04,\n",
       "       4.29561133e-03, 3.35681101e-04, 3.35681101e-04, 1.08996031e-01,\n",
       "       7.17944644e-03, 1.10006348e-01, 7.17944644e-03, 1.21666897e-04,\n",
       "       8.81121528e-02, 1.08996031e-01, 3.62235752e-01, 7.17944644e-03,\n",
       "       4.29561133e-03, 4.39258141e-03, 1.21666897e-04, 7.51481015e-03,\n",
       "       2.81583442e-01, 1.21666897e-04, 4.39258141e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 4.90534510e-03, 7.51481015e-03, 3.15940339e-01,\n",
       "       1.21666897e-04, 1.21666897e-04, 2.80065041e-01, 5.10803180e-03,\n",
       "       1.08437780e-01, 1.21666897e-04, 3.35681101e-04, 5.10803180e-03,\n",
       "       4.77390916e-03, 7.17944644e-03, 4.39258141e-03, 7.51481015e-03,\n",
       "       5.41332541e-03, 3.35681101e-04, 6.22246371e-02, 4.72346940e-01,\n",
       "       1.21666897e-04, 7.51481015e-03, 9.81830522e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 1.21666897e-04, 4.90534510e-03, 3.35681101e-04,\n",
       "       1.21666897e-04, 3.35681101e-04, 1.21666897e-04, 7.51481015e-03,\n",
       "       1.21666897e-04, 3.35681101e-04, 4.90534510e-03, 1.21666897e-04,\n",
       "       1.21666897e-04, 5.34453945e-01, 7.51481015e-03, 4.96543184e-03,\n",
       "       7.54612442e-02, 2.80065041e-01, 4.85411987e-03, 9.18977481e-01,\n",
       "       7.51481015e-03, 7.17944644e-03, 7.17944644e-03, 4.77390916e-03,\n",
       "       3.35681101e-04, 4.29561133e-03, 1.21666897e-04, 7.51481015e-03,\n",
       "       4.77390916e-03, 7.17944644e-03, 3.35681101e-04, 5.10803180e-03,\n",
       "       3.35681101e-04, 3.35681101e-04, 5.34453945e-01, 4.90534510e-03,\n",
       "       4.77390916e-03, 3.35681101e-04, 1.21666897e-04, 7.17944644e-03,\n",
       "       6.84261628e-03, 3.35681101e-04, 7.51481015e-03, 3.35681101e-04,\n",
       "       4.39258141e-03, 1.21666897e-04, 5.24955018e-03, 3.35681101e-04,\n",
       "       1.21666897e-04, 3.35681101e-04, 3.35681101e-04, 4.76022306e-01,\n",
       "       3.35681101e-04, 3.35681101e-04, 7.17944644e-03, 7.17944644e-03,\n",
       "       1.21666897e-04, 7.17944644e-03, 3.35681101e-04, 3.35681101e-04,\n",
       "       4.39258141e-03, 1.21666897e-04, 9.81830522e-03, 1.21666897e-04,\n",
       "       4.90534510e-03, 1.21666897e-04, 1.21666897e-04, 7.07287026e-03,\n",
       "       7.51481015e-03, 5.24955018e-03, 1.11446859e-02, 1.21666897e-04,\n",
       "       3.35681101e-04, 3.35681101e-04, 3.71802646e-01, 1.21666897e-04,\n",
       "       9.42128288e-03, 3.35681101e-04, 7.51481015e-03, 7.07287026e-03,\n",
       "       3.35681101e-04, 5.24955018e-03, 4.29561133e-03, 1.21666897e-04,\n",
       "       4.39258141e-03, 1.21666897e-04, 4.39258141e-03, 7.17944644e-03,\n",
       "       7.51481015e-03, 6.48213363e-03, 1.21666897e-04, 7.51481015e-03,\n",
       "       3.35681101e-04, 7.17944644e-03, 1.21666897e-04, 3.35681101e-04,\n",
       "       1.21666897e-04, 1.21666897e-04, 4.39258141e-03, 7.51481015e-03,\n",
       "       8.40301969e-03, 7.62528650e-02, 7.17944644e-03, 1.21666897e-04,\n",
       "       2.80947544e-01, 7.17944644e-03, 6.59504908e-01, 8.81121528e-02,\n",
       "       3.35681101e-04, 7.63457319e-02, 1.21666897e-04, 1.21666897e-04,\n",
       "       3.35681101e-04, 4.39258141e-03, 1.21666897e-04, 3.35681101e-04,\n",
       "       4.39258141e-03, 2.22549640e-01, 1.08785732e-02, 3.35681101e-04,\n",
       "       7.01761750e-03, 1.21666897e-04, 7.51481015e-03, 1.21666897e-04,\n",
       "       4.39258141e-03, 3.35681101e-04, 3.35681101e-04, 3.35681101e-04,\n",
       "       1.21666897e-04, 7.51481015e-03, 7.17944644e-03, 3.35681101e-04,\n",
       "       7.51481015e-03, 7.51481015e-03, 3.35681101e-04, 1.21666897e-04,\n",
       "       7.17944644e-03, 4.90534510e-03, 6.46969370e-01, 1.21666897e-04,\n",
       "       8.84858370e-02, 1.21666897e-04, 1.21666897e-04, 7.51481015e-03,\n",
       "       3.35681101e-04, 7.62528650e-02, 7.51481015e-03, 7.51481015e-03,\n",
       "       1.38465923e-02, 5.34453945e-01, 7.07287026e-03, 7.17944644e-03,\n",
       "       3.35681101e-04, 1.21666897e-04, 4.39258141e-03, 1.21666897e-04,\n",
       "       5.24955018e-03, 7.17944644e-03, 3.35681101e-04, 4.90534510e-03,\n",
       "       1.21666897e-04, 9.05153632e-01, 6.96543224e-03, 1.21666897e-04,\n",
       "       1.21666897e-04, 1.11528389e-01, 3.35681101e-04, 7.17944644e-03,\n",
       "       4.90534510e-03, 8.32807784e-03, 7.17944644e-03, 7.07287026e-03,\n",
       "       1.21666897e-04, 1.21666897e-04, 7.17944644e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 7.66800364e-02, 7.51481015e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 1.21666897e-04, 3.35681101e-04, 1.21666897e-04,\n",
       "       1.21666897e-04, 1.21666897e-04, 1.21666897e-04, 1.21666897e-04,\n",
       "       3.35681101e-04, 3.35681101e-04, 4.29561133e-03, 4.29561133e-03,\n",
       "       4.90534510e-03, 3.35681101e-04, 1.21666897e-04, 3.35681101e-04,\n",
       "       7.17944644e-03, 2.23693915e-01, 1.21666897e-04, 7.17944644e-03,\n",
       "       5.10803180e-03, 3.15940339e-01, 1.21666897e-04, 1.21666897e-04,\n",
       "       1.21666897e-04, 3.35681101e-04, 3.77852218e-01, 9.39986289e-01,\n",
       "       7.51481015e-03, 1.21666897e-04, 5.54224986e-03, 3.35681101e-04,\n",
       "       3.35681101e-04, 8.32807784e-03, 7.17944644e-03, 4.90534510e-03,\n",
       "       7.88870378e-01, 1.21666897e-04, 6.38068821e-02, 4.90534510e-03,\n",
       "       3.35681101e-04, 9.81830522e-03, 6.38068821e-02, 3.35681101e-04,\n",
       "       7.51481015e-03, 7.62528650e-02, 4.39258141e-03, 1.21666897e-04])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_md = RandomForestClassifier(max_depth=3, min_samples_leaf=7, min_samples_split=10, n_estimators=500).fit(X_train_5, Y_train)\n",
    "\n",
    "# Predicting on validation and test\n",
    "RF_val_pred = RF_md.predict_proba(X_val_5)[:,1]\n",
    "RF_test_pred = RF_md.predict_proba(test_5)[:,1]\n",
    "\n",
    "RF_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a84eb5",
   "metadata": {},
   "source": [
    "### The Best Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4da97a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.22791077e-05, 2.59084845e-05, 1.95182522e-06, ...,\n",
       "       1.21058708e-05, 2.59295689e-05, 2.59294426e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_md = SVC(C=0.01, gamma=0.1, kernel='sigmoid', probability=True).fit(X_train_5, Y_train)\n",
    "\n",
    "# Predicting on validation and test\n",
    "SVC_val_pred = SVC_md.predict_proba(X_val_5)[:,1]\n",
    "SVC_test_pred = SVC_md.predict_proba(test_5)[:,1]\n",
    "\n",
    "SVC_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275878e",
   "metadata": {},
   "source": [
    "### The Best AdaBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_md = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
    "                                                         min_samples_leaf=5,\n",
    "                                                         min_samples_split=10),\n",
    "                                                         learning_rate=0.01, n_estimators=300).fit(X_train_7, Y_train)\n",
    "# Predicting on validation and test\n",
    "ADA_val_pred = ADA_md.predict_proba(X_val_7)[:,1]\n",
    "ADA_test_pred = ADA_md.predict_proba(test_7)[:,1]\n",
    "\n",
    "ADA_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1c2a0",
   "metadata": {},
   "source": [
    "### The Best XGBClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37fc059f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0129512 , 0.07681634, 0.00648836, 0.00495164, 0.01273502,\n",
       "       0.00648836, 0.0048738 , 0.37137148, 0.00488855, 0.00483632,\n",
       "       0.00648836, 0.00483632, 0.00495164, 0.00648836, 0.01660819,\n",
       "       0.00648836, 0.1054444 , 0.00495164, 0.0062665 , 0.01273502,\n",
       "       0.01341279, 0.01273502, 0.00488228, 0.12237891, 0.0134928 ,\n",
       "       0.00485756, 0.00483632, 0.01616401, 0.00699993, 0.00488855,\n",
       "       0.00648836, 0.0062665 , 0.01273502, 0.01384391, 0.00658739,\n",
       "       0.10276256, 0.00495164, 0.00490766, 0.00488223, 0.01273502,\n",
       "       0.00648836, 0.00495164, 0.00483632, 0.00495164, 0.00648836,\n",
       "       0.10276256, 0.00485756, 0.00648836, 0.00648836, 0.00483632,\n",
       "       0.00592595, 0.00485756, 0.00699993, 0.07644632, 0.00483632,\n",
       "       0.01273502, 0.00488223, 0.00488223, 0.00495164, 0.00648836,\n",
       "       0.00648836, 0.08025405, 0.0062665 , 0.00483632, 0.00490561,\n",
       "       0.00483632, 0.15839788, 0.00495164, 0.00656299, 0.00699993,\n",
       "       0.00483632, 0.00648836, 0.12237891, 0.00485836, 0.00485756,\n",
       "       0.00485756, 0.00485836, 0.07681634, 0.00485756, 0.07780735,\n",
       "       0.0062665 , 0.00488855, 0.00488855, 0.01559756, 0.00483632,\n",
       "       0.00483632, 0.00488228, 0.00658915, 0.00651919, 0.00658915,\n",
       "       0.01389331, 0.00485836, 0.1153534 , 0.01660819, 0.0129512 ,\n",
       "       0.19226423, 0.00483632, 0.00699993, 0.01271169, 0.00483632,\n",
       "       0.00648836, 0.11979081, 0.00485836, 0.00483632, 0.0062665 ,\n",
       "       0.00483632, 0.00495164, 0.12237891, 0.01273502, 0.12237891,\n",
       "       0.01273502, 0.0048738 , 0.10014918, 0.12237891, 0.3227792 ,\n",
       "       0.01616401, 0.00631871, 0.00648836, 0.00485836, 0.01333227,\n",
       "       0.2395292 , 0.00495164, 0.00648836, 0.00483632, 0.0049349 ,\n",
       "       0.00648836, 0.01375415, 0.27656916, 0.00485836, 0.00490766,\n",
       "       0.2565304 , 0.00658915, 0.12237891, 0.00485836, 0.00495164,\n",
       "       0.00656299, 0.00648836, 0.0160664 , 0.00648836, 0.01429874,\n",
       "       0.00699993, 0.0049349 , 0.07644632, 0.5154844 , 0.00490766,\n",
       "       0.01381136, 0.00675084, 0.00495164, 0.00483632, 0.0048738 ,\n",
       "       0.00648836, 0.00483632, 0.00488223, 0.00483632, 0.00485756,\n",
       "       0.01341279, 0.00485836, 0.00483632, 0.00648836, 0.00488223,\n",
       "       0.00488029, 0.6212687 , 0.0134928 , 0.00699993, 0.10276256,\n",
       "       0.2588442 , 0.00651919, 0.8539867 , 0.01407578, 0.01273502,\n",
       "       0.01273502, 0.00648836, 0.00495164, 0.0062665 , 0.00488855,\n",
       "       0.0134928 , 0.00648836, 0.01273502, 0.00483632, 0.00658915,\n",
       "       0.00483632, 0.00495164, 0.6212687 , 0.00648836, 0.00648836,\n",
       "       0.00483632, 0.00488228, 0.01597593, 0.00689402, 0.0049349 ,\n",
       "       0.01389331, 0.00495164, 0.00648836, 0.00485836, 0.00648836,\n",
       "       0.00495164, 0.00488223, 0.00483632, 0.00483632, 0.47440362,\n",
       "       0.00483632, 0.00495164, 0.01273502, 0.01279642, 0.00488228,\n",
       "       0.01597593, 0.00495443, 0.00483632, 0.00648836, 0.00495164,\n",
       "       0.00675084, 0.00485756, 0.00648836, 0.00485836, 0.00490766,\n",
       "       0.01340604, 0.01333227, 0.00648836, 0.00648836, 0.00488228,\n",
       "       0.00483632, 0.00495443, 0.35660377, 0.00488855, 0.00675084,\n",
       "       0.00483632, 0.01407578, 0.01340604, 0.00483632, 0.00648836,\n",
       "       0.0062665 , 0.0048738 , 0.00651919, 0.00495164, 0.00648836,\n",
       "       0.01660819, 0.01381136, 0.0068329 , 0.00488855, 0.0137044 ,\n",
       "       0.00483632, 0.01597593, 0.00488855, 0.00483632, 0.00488855,\n",
       "       0.00488223, 0.00648836, 0.01375415, 0.00699993, 0.07554732,\n",
       "       0.01273502, 0.00485756, 0.25384274, 0.01559756, 0.7183373 ,\n",
       "       0.10014918, 0.00495164, 0.09779082, 0.0048738 , 0.00485756,\n",
       "       0.00483632, 0.00651919, 0.00488228, 0.00495164, 0.00648836,\n",
       "       0.18985547, 0.00699993, 0.00483632, 0.0068329 , 0.00488223,\n",
       "       0.01407578, 0.00490766, 0.00648836, 0.00483632, 0.00495164,\n",
       "       0.00495443, 0.0048738 , 0.0137044 , 0.01621822, 0.00483632,\n",
       "       0.01399462, 0.01429874, 0.00495443, 0.00488228, 0.01273502,\n",
       "       0.00648836, 0.70746785, 0.00485836, 0.10239425, 0.00485836,\n",
       "       0.00485756, 0.01389331, 0.00483632, 0.07780735, 0.01308496,\n",
       "       0.0134928 , 0.0062665 , 0.6087159 , 0.01345423, 0.01273502,\n",
       "       0.00495443, 0.0048738 , 0.00648836, 0.00485756, 0.00648836,\n",
       "       0.01273502, 0.00483632, 0.00648836, 0.00485756, 0.85132194,\n",
       "       0.0164556 , 0.00488855, 0.00488855, 0.12237891, 0.00483632,\n",
       "       0.01279642, 0.00648836, 0.00699993, 0.01273502, 0.01639808,\n",
       "       0.00485756, 0.00488029, 0.01616401, 0.00483632, 0.00483632,\n",
       "       0.10085495, 0.01389331, 0.00495164, 0.00483632, 0.00485836,\n",
       "       0.00483632, 0.00488228, 0.00485756, 0.00485756, 0.00488855,\n",
       "       0.00488855, 0.00495164, 0.00483632, 0.0062665 , 0.0062665 ,\n",
       "       0.00648836, 0.00483632, 0.00488223, 0.00483632, 0.01273502,\n",
       "       0.19226423, 0.00485836, 0.01273502, 0.00658915, 0.27717268,\n",
       "       0.00488029, 0.00485756, 0.00488855, 0.00495164, 0.3541311 ,\n",
       "       0.8837017 , 0.01333227, 0.00485836, 0.00648836, 0.00483632,\n",
       "       0.00495164, 0.00699993, 0.01273502, 0.00648836, 0.8412026 ,\n",
       "       0.00485836, 0.07681634, 0.00648836, 0.0049349 , 0.00675084,\n",
       "       0.07681634, 0.00483632, 0.0137044 , 0.07816137, 0.00648836,\n",
       "       0.00485836], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost_md = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "              eval_metric='logloss', gamma=0.3, gpu_id=-1, importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
    "              max_depth=5, min_child_weight=5,\n",
    "              monotone_constraints='()', n_estimators=500, n_jobs=4,\n",
    "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None).fit(X_train_5, Y_train)\n",
    "\n",
    "# Predicting on validation and test\n",
    "XGBoost_val_pred = XGBoost_md.predict_proba(X_val_5)[:,1]\n",
    "XGBoost_test_pred = XGBoost_md.predict_proba(test_5)[:,1]\n",
    "\n",
    "XGBoost_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esemble_train = pd.DataFrame({'RF': RF_val_pred, \"SVC\": SVC_val_pred, 'ADA': ADA_val_pred, \"XGBoost\": XGBoost_val_pred, \"Y_val\": Y_val})\n",
    "esemble_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esemble_test = pd.DataFrame({\"RF_preds_test\": RF_test_pred, \"SVC_preds_test\": SVC_test_pred, \"ADA_preds_test\": ADA_test_pred, \"XGBoost_preds_test\": XGBoost_test_pred})\n",
    "esemble_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a90a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ensemble\n",
    "RF_val_pred = pd.DataFrame(RF_val_pred)\n",
    "SVC_val_pred = pd.DataFrame(SVC_val_pred)\n",
    "ADA_val_pred = pd.DataFrame(ADA_val_pred)\n",
    "XGBoost_val_pred = pd.DataFrame(XGBoost_val_pred)\n",
    "Y = esemble_train['Y_val']\n",
    "RF_test_pred = pd.DataFrame(RF_test_pred)\n",
    "SVC_test_pred = pd.DataFrame(SVC_test_pred)\n",
    "ADA_test_pred = pd.DataFrame(ADA_test_pred)\n",
    "XGBoost_test_pred = pd.DataFrame(XGBoost_test_pred)\n",
    "\n",
    "ensemble = Ensemble.ensemble(RF_val_pred, SVC_val_pred, ADA_val_pred, XGBoost_val_pred, Y, RF_test_pred, SVC_test_pred, ADA_test_pred, XGBoost_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ce562",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ensemble)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f720f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = pd.DataFrame(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c28810",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = pd.concat([RF_test_pred, SVC_test_pred, ADA_test_pred, ensemble], axis = 1)\n",
    "Predictions.columns = ['RF_test_pred', 'SVC_test_pred', 'ADA_test_pred', 'Ensemble']\n",
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelyhoods = pd.DataFrame({'Likelyhoods': Predictions['Ensemble']})\n",
    "likelyhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelyhoods.to_csv(\"likelyhoods.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd92459",
   "metadata": {},
   "source": [
    "# Indentifyung the optimal cut-off value\n",
    "opt_cutoff = cost_function_cutoff(Y_val, SVC_val_pred)\n",
    "\n",
    "# Changing the likelihoods to labels\n",
    "SVC_label = np.where(SVC_test_pred < opt_cutoff, 0, 1)\n",
    "\n",
    "# Computing the confusion matrix\n",
    "X = confusion_matrix(Y_test, SVC_label)\n",
    "print(X)\n",
    "print('The cost of the SVC model is: ', -1500*X[1,0] - 1000*X[0,1] + 500*X[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74458550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
